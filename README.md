# Logging System

The Logging System is a component of the NebulOuS project, designed to facilitate efficient and scalable logging within cloud and edge computing environments. It is built using the **EFK Stack** (Elasticsearch, Fluentd, and Kibana) to provide a complete and robust logging solution.

> **Important**: This is a Proof of Concept (PoC) that has been deployed on a three-node cluster, with log data currently being persisted in an **ephemeral state**. For production use, this should be updated to use **persistent storage** to ensure data durability and reliability.

## Introduction

The Logging System provides a centralized platform for collecting, storing, and analyzing logs generated by various components of the NebulOuS ecosystem. It ensures reliable log management, aiding in monitoring, debugging, and optimizing system performance.

## Features

- **Centralized Log Collection**: Aggregates logs from multiple sources for unified analysis.
- **Scalability**: Handles large volumes of log data efficiently.
- **Real-time Monitoring**: Supports real-time log streaming and alerting.
- **Extensibility**: Easily integrates with other monitoring and analytics tools.

## Main Components

### **1. Log Aggregator**

- **Purpose**: Collects logs from multiple sources (e.g., applications, services, and nodes).
- **Implementation**: Based on **Fluentd** for log collection and processing.
- **Key Features**:
  - Parses log data into structured formats.
  - Routes logs to appropriate destinations (e.g., storage or external systems).

---

### **2. Log Storage**

- **Purpose**: Stores logs for querying and analysis.
- **Implementation**: Uses **ElasticSearch** for fast and scalable log storage and indexing.
- **Key Features**:
  - Allows for searching logs using powerful queries.
  - Provides redundancy and scalability for large datasets.

---

### **3. Visualization**

- **Purpose**: Provides a user interface for analyzing and understanding logs.
- **Implementation**: Uses **Kibana** as a frontend dashboard.
- **Key Features**:
  - Displays log data visually through charts, graphs, and timelines.
  - Enables filtering and exploring logs interactively.

---

## Things to Consider

### **1. Monitoring and Alerting**

- **Purpose**: Monitors logs and triggers alerts based on defined rules.
- **Implementation**: Integrates with **Alertmanager** or other alerting tools.
- **Key Features**:
  - Sends notifications when anomalies or critical issues are detected.
  - Supports custom thresholds and log pattern matching.

---

### **2. Ingestion Pipeline**

- **Purpose**: Ensures logs are processed and normalized for consistency.
- **Implementation**: Configurable pipelines in Fluentd.
- **Key Features**:
  - Handles log enrichment (e.g., adding metadata like timestamps, source IPs).
  - Filters out unnecessary log data to optimize storage.

---

## Starting and Stopping the Logging System

To simplify the management of the Logging System, we have provided scripts for:

- **create-ns.sh**: Creates appropriate namespaces
- **deploy-elastic-cluster.sh**: Applies required manifests to deploy an Elastic Cluster
- **deploy-kibana.sh**: Applies required manifests to deploy Kibana
- **deploy-fluentd.sh**: Applies required manifests to deploy Fluentd DaemonSet
- **deploy-sample-log-pod.sh**: Applies required manifests to deploy a sample log pod
- **remove-efk.sh**: Removes all namespaces and Elastic Cluster PVs

These components work together to provide a robust logging solution, ensuring reliable collection, storage, analysis, and alerting of log data.
